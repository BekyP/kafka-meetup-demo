name=payments-connector-hdfs
connector.class=io.confluent.connect.hdfs.HdfsSinkConnector
tasks.max=1
topics=payment_complete

key.converter=org.apache.kafka.connect.storage.StringConverter
value.converter=io.confluent.connect.avro.AvroConverter
key.converter.schema.registry.url=http://schema-registry:8081
value.converter.schema.registry.url=http://schema-registry:8081
schema.compatibility=BACKWARD

# HDFS configuration
# Use store.url instead of hdfs.url (deprecated) in later versions. Property store.url does not work, yet
hdfs.url=hdfs://namenode:8020
hadoop.conf.dir=/etc/hadoop/conf
hadoop.home=/opt/cloudera/parcels/CDH/lib/hadoop
topics.dir=/topics
logs.dir=/logs

# Connector configuration
format.class=io.confluent.connect.hdfs.avro.AvroFormat
flush.size=200
rotate.interval.ms=6000

# Hive integration
hive.integration=true
hive.metastore.uris=thrift://hive-metastore:9083
hive.conf.dir=/opt/hive/conf
hive.home=/opt/hive
hive.database=payments

# Partitioning
partitioner.class=io.confluent.connect.hdfs.partitioner.TimeBasedPartitioner
partition.duration.ms=86400000
path.format='day'=YYYYMMdd
locale=sk_SK
timezone=Europe/Bratislava
timestamp.extractor=RecordField
timestamp.field=TIMESTAMP

# Transformations
transforms=InsertMetadata,RenameField
transforms.InsertMetadata.type=org.apache.kafka.connect.transforms.InsertField$Value
transforms.InsertMetadata.partition.field=partition
transforms.InsertMetadata.offset.field=offset
transforms.RenameField.type=org.apache.kafka.connect.transforms.ReplaceField$Value
transforms.RenameField.renames=ID:kafka_key
