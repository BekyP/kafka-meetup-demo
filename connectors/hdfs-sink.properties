name=test-connector
connector.class=io.confluent.connect.hdfs.HdfsSinkConnector
tasks.max=1
topics=test-avro-topic

key.converter=io.confluent.connect.avro.AvroConverter
value.converter=io.confluent.connect.avro.AvroConverter
key.converter.schema.registry.url=http://schema-registry:8081
value.converter.schema.registry.url=http://schema-registry:8081
schema.compatibility=BACKWARD

# HDFS configuration
# Use store.url instead of hdfs.url (deprecated) in later versions. Property store.url does not work, yet
hdfs.url=hdfs://namenode:8020
hadoop.conf.dir=/etc/hadoop/conf
hadoop.home=/opt/cloudera/parcels/CDH/lib/hadoop
topics.dir=/topics
logs.dir=/logs

# Connector configuration
format.class=io.confluent.connect.hdfs.avro.AvroFormat
flush.size=20000
rotate.interval.ms=60000

# Hive integration
hive.integration=true
hive.metastore.uris=thrift://hive-metastore:9083
hive.conf.dir=/opt/hive/conf
hive.home=/opt/hive
hive.database=test

# Transformations
transforms=InsertMetadata
transforms.InsertMetadata.type=org.apache.kafka.connect.transforms.InsertField$Value
transforms.InsertMetadata.partition.field=partition
transforms.InsertMetadata.offset.field=offset
